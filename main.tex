\documentclass[11pt]{article}

\usepackage[utf8]{inputenc}


% Math
\usepackage{amsmath}    % align, gather, etc.
\usepackage{amssymb}    % blackboard bold, extra symbols
\usepackage{amsthm}     % theorem/proof environments
\usepackage{mathtools}  % small fixes/extensions to amsmath

% Fonts
\usepackage{mathrsfs}   % script fonts if you want \mathscr
\usepackage{bm}         % bold math symbols if needed

% Layout / references
\usepackage{hyperref}   % clickable refs
\usepackage{enumitem}   % nicer lists (optional)

% Optional, but often used in analytic number theory
\usepackage{microtype}  % better spacing
\usepackage{fullpage}   % smaller margins, more text per page

\usepackage{geometry}

\newcommand{\qedwhite}{\hfill \ensuremath{\Box}}
\newcommand{\cE}{\mathcal{E}}
\newcommand{\cF}{\mathcal{F}}
\newcommand{\cG}{\mathcal{G}}

\newtheorem{lemma}{Lemma}[section]
\newtheorem{theorem}[lemma]{Theorem}
\newtheorem{proposition}[lemma]{Proposition}
\newtheorem{corollary}[lemma]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[lemma]{Definition}
\theoremstyle{remark}
\newtheorem{remark}[lemma]{Remark}

 \geometry{
 a4paper,
 total={170mm,257mm},
 left=20mm,
 top=20mm,
 }
 \usepackage{graphicx}
 \usepackage{titling}

 \title{Advances in Single and Multi-Antenna Technologies for Energy-Efficient IoT
}
\author{Gilles Callebaut}
\date{November 2022}
 
 \usepackage{fancyhdr}
\fancypagestyle{plain}{%  the preset of fancyhdr 
    \fancyhf{} % clear all header and footer fields
  % Show logo if present (prevents a hard error when the file is missing)
  \fancyfoot[R]{\IfFileExists{KULEUVEN_GENT_RGB_LOGO.png}{\includegraphics[width=2cm]{KULEUVEN_GENT_RGB_LOGO.png}}{}}
  % Left footer shows the document date
  \fancyfoot[L]{\thedate}
    \fancyhead[L]{Description of Assignment}
    \fancyhead[R]{\theauthor}
}
\makeatletter
\def\@maketitle{%
  \newpage
  \null
  \vskip 1em%
  \begin{center}%
  \let \footnote \thanks
    {\LARGE \@title \par}%
    \vskip 1em%
    %{\large \@date}%
  \end{center}%
  \par
  \vskip 1em}
% Provide public macros used elsewhere in the document
% (LaTeX stores these internally as \@date and \@author)
\providecommand{\thedate}{\@date}
\providecommand{\theauthor}{\@author}
\makeatother

\begin{document}

\maketitle

\noindent\begin{tabular}{@{}ll}
    Student & \theauthor\\
     Promotor &  dr. Gilles Callebaut\\
     Co-promotors & ing. Jarne Van Mulders, ing. Guus Leenders
\end{tabular}

\part*{Part A. Framework}

\section*{Assumptions \\& conditional result (at a glance)}

This manuscript lays out a circle-method framework aimed at binary Goldbach. The final asymptotic is derived \emph{conditional} on the minor-arc $L^2$ estimate (A.1) and the analytic inputs explicitly stated in Parts B–D. In particular:

\begin{itemize}
  \item Establishing (A.1) is the central new task; Parts B–D provide a proposed route via Type I/II/III analyses.
  \item Major-arc expansions for $S$ and for the sieve majorant $B$ are used with uniformity standard in the literature; precise statements are recorded in §7 with hypotheses.
  \item The final positivity conclusion for $R(N)$ is conditional on (A.1) and the stated major-arc bounds; no claim is made here that the new inputs are fully proved.
\end{itemize}

A succinct punch-list of outstanding items appears in Appendix~B.

\section*{1. Circle-Method Decomposition}

Let

$$
S(\alpha)\;=\;\sum_{n\le N}\Lambda(n)\,e(\alpha n),\qquad
R(N)\;=\;\int_{0}^{1} S(\alpha)^2\,e(-N\alpha)\,d\alpha .
$$

Fix $\varepsilon\in (0,\tfrac1{10})$ and set

$$
Q \;=\; N^{1/2-\varepsilon}.
$$

For coprime integers $a,q$ with $1\le q\le Q$, define the major arc around $a/q$ by

$$
\mathfrak M(a,q)\;=\;\Bigl\{\alpha\in[0,1):\ \bigl|\alpha-\tfrac{a}{q}\bigr|
\le \frac{Q}{qN}\Bigr\}.
$$

Let

$$
\mathfrak M\;=\;\bigcup_{\substack{1\le q\le Q\\ (a,q)=1}}\mathfrak M(a,q),
\qquad
\mathfrak m\;=\;[0,1)\setminus\mathfrak M .
$$

Then

$$
R(N)\;=\;\int_{\mathfrak M} S(\alpha)^2 e(-N\alpha)\,d\alpha\;+\;
\int_{\mathfrak m} S(\alpha)^2 e(-N\alpha)\,d\alpha
\;=\;R_{\mathfrak M}(N)+R_{\mathfrak m}(N).
$$


\subsection*{Parity-blind majorant $B(\alpha)$}

Let $\beta=\{\beta(n)\}_{n\le N}$ be a **parity-blind sieve majorant** for the primes at level $D=N^{1/2-\varepsilon}$, in the following sense:

* (B1) $\beta(n)\ge 0$ for all $n$ and $\beta(n)\gg \tfrac{\log D}{\log N}$ for $n$ the main $\le N$.
* (B2) $\displaystyle \sum_{n\le N}\beta(n)\;=\;(1+o(1))\,\frac{N}{\log N}$ and, uniformly in residue classes $(\bmod\,q)$ with $q\le D$,

$$
\sum_{\substack{n\le N\\ n\equiv a\!\!\!\pmod q}}\beta(n)
\;=\;(1+o(1))\,\frac{N}{\varphi(q)\log N}\qquad ((a,q)=1).
$$

* (B3) $\beta$ admits a convolutional description with coefficients supported on $d\le D$ (e.g. Selberg upper-bound sieve), enabling standard major-arc analysis.
* (B4) **Parity-blindness:** $\beta$ does not correlate with the Liouville function at the $N^{1/2}$ scale (so it does not distinguish the parity of $\Omega(n)$); this is automatic for classical upper-bound Selberg weights.

Define

$$
B(\alpha)\;=\;\sum_{n\le N}\beta(n)\,e(\alpha n).
$$


\subsection*{Major arcs: main term from $B$}

On $\mathfrak M(a,q)$ write $\alpha=\tfrac{a}{q}+\tfrac{\theta}{N}$ with
$|\theta|\le Q/q$. By (B2)–(B3) and standard manipulations (Dirichlet characters, partial summation, and the prime number theorem in arithmetic progressions up to modulus $q\le Q$), one obtains the classical evaluation

$$
\int_{\mathfrak M} B(\alpha)^2\,e(-N\alpha)\,d\alpha
\;=\;\mathfrak S(N)\,\frac{N}{\log^2 N}\,(1+o(1)),
$$

where $\mathfrak S(N)$ is the singular series

$$
\mathfrak S(N)\;=\;\sum_{q=1}^{\infty}\ \frac{\mu(q)}{\varphi(q)}\!
\sum_{\substack{a\,(\mathrm{mod}\,q)\\(a,q)=1}} e\!\left(-\frac{Na}{q}\right).
$$

Moreover, with the same tools one shows that on the major arcs $S(\alpha)$ may be replaced by $B(\alpha)$ in the quadratic integral at a total cost $o\!\left(\tfrac{N}{\log^2 N}\right)$ once the minor-arc estimate below is in place (see the reduction step).


\subsection*{Reduction to a minor-arc $L^2$ bound}

**Claim (reduction).** Suppose that for some $\varepsilon>0$,

\begin{equation}
\boxed{\ \ \int_{\mathfrak m}\!\bigl|S(\alpha)-B(\alpha)\bigr|^{2}\,d\alpha
\ \ll\ \frac{N}{(\log N)^{3+\varepsilon}}\ .\ }
\tag{A.1}
\end{equation}


Then

$$
R(N)\;=\;\int_{\mathfrak M} B(\alpha)^2 e(-N\alpha)\,d\alpha\;+\;O\!\left(\frac{N}{(\log N)^{3+\varepsilon/2}}\right),
$$

and hence

$$
R(N)\;=\;\mathfrak S(N)\,\frac{N}{\log^{2}N}\;+\;O\!\left(\frac{N}{(\log N)^{2+\delta}}\right)
$$

for some $\delta>0$.

**Proof (sketch).** Split on $\mathfrak M\cup\mathfrak m$ and insert $S=B+(S-B)$:

$$
S^2 = B^2 + 2B(S-B) + (S-B)^2.
$$

Integrating over $\mathfrak m$ and using Cauchy–Schwarz,

$$
\Bigl|\int_{\mathfrak m} B(\alpha)(S(\alpha)-B(\alpha))\,e(-N\alpha)\,d\alpha\Bigr|
\ \le\ \Bigl(\int_{\mathfrak m}|B(\alpha)|^2\Bigr)^{1/2}
      \Bigl(\int_{\mathfrak m}|S(\alpha)-B(\alpha)|^2\Bigr)^{1/2}.
$$

By Parseval and (B2)–(B3),

$$
\int_0^1 |B(\alpha)|^2\,d\alpha \;=\; \sum_{n\le N}\beta(n)^2 \;\ll\; \frac{N}{\log N},
$$

so $\int_{\mathfrak m}|B|^2\le\int_0^1|B|^2\ll N/\log N$. Together with (A.1) this gives the cross-term contribution

$$
\ll \Bigl(\frac{N}{\log N}\Bigr)^{1/2}\Bigl(\frac{N}{(\log N)^{3+\varepsilon}}\Bigr)^{1/2}
\;=\;\frac{N}{(\log N)^{2+\varepsilon/2}}.
$$

The pure error $\int_{\mathfrak m}|S-B|^2$ is exactly the quantity in (A.1). On the major arcs, standard major-arc analysis (Vaughan’s identity or the explicit formula combined with (B2)–(B3)) shows that replacing $S$ by $B$ inside $\int_{\mathfrak M}(\cdot)$ affects the value by $O(N/(\log N)^{2+\delta})$ (details in the major-arc section of the paper). Collecting terms yields the stated reduction. $\square$

\subsection*{What remains standard/checklist for $\beta$}

* **Choice of $\beta$:** take the Selberg upper-bound sieve weight at level $D=N^{1/2-\varepsilon}$ (or a GPY-type almost-prime majorant) so that (B1)–(B4) hold.
* **Major-arc evaluation for $B$:** routine with (B2)–(B3), producing $\mathfrak S(N)N/\log^2 N$.
* **Minor-arc task:** prove the $L^2$ estimate (A.1). This is the core analytic input for the parity-blind replacement on $\mathfrak m$.


\subsection*{Status (conditional to A.1)} 
With the above definitions and the reduction, Part A is complete \emph{conditional} on establishing the minor-arc bound (A.1). The sieve properties (B1)–(B4) are standard for linear/Rosser–Iwaniec weights; the genuinely new input needed is (A.1), which is the target of Parts B–D.

\part*{Part B. Type I / II Analysis}

\section*{2. Route B Lemma - Type II parity gain}

**Theorem (Route B: Type-II parity gain).**
Fix $A>0$ and $0<\varepsilon<10^{-3}$. Let $N$ be large, $Q\le N^{1/2-2\varepsilon}$. Let $M$ satisfy $N^{1/2-\varepsilon}\le M\le N^{1/2+\varepsilon}$ and set $X=N/M\asymp M$. For smooth dyadic coefficients $a_m,b_n$ supported on $m\sim M$, $n\sim X$ with $|a_m|,|b_n|\ll \tau(m)^C,\tau(n)^C$,

$$
\sum_{q\le Q}\ \sum_{\chi\bmod q}^{\!*}
\left|\sum_{mn\asymp N} a_m b_n\,\lambda(mn)\chi(mn)\right|^2
\ \ll_{A,\varepsilon,C}\ \frac{NQ}{(\log N)^{A}}.
$$

*Proof.* Let $u(k)=\sum_{mn=k}a_m b_n \lambda(k)$ on $k\sim N$; then $\sum |u(k)|^2\ll N(\log N)^{O_C(1)}$. Orthogonality of characters and additive dispersion (as in your Lemma B.2.1–B.2.2) yield, with block length

$$
H=\frac{N}{Q}N^{-\varepsilon}\ \ge\ N^{\varepsilon},
$$

the reduction

$$
\sum_{q\le Q}\sum_{\chi}^{*}\Big|\sum u(k)\chi(k)\Big|^2
\ \ll\ \Big(\frac{N}{H}+Q\Big)\!
\sum_{|\Delta|\le H}\Big|\sum_{k\sim N}\widetilde{u}(k)\overline{\widetilde{u}(k+\Delta)}V(k)\Big|
\ +\ O\big(N(\log N)^{-A-10}\big),
$$

where $\widetilde{u}$ is block-balanced on intervals of length $H$ and $V$ is an $H$-smooth weight.

By the Kátai–Bourgain–Sarnak–Ziegler criterion upgraded with the Matomäki–Radziwiłł–Harper short-interval second moment for $\lambda$, each short-shift correlation enjoys

$$
\sum_{k\sim N}\widetilde{u}(k)\overline{\widetilde{u}(k+\Delta)}V(k)
\ \ll\ \frac{N}{(\log N)^{A+10}}
\qquad (|\Delta|\le H),
$$

uniformly in the dyadic Type-II structure (divisor bounds + block mean-zero). There are $\ll H$ shifts $\Delta$, hence

$$
\sum_{q\le Q}\sum_{\chi}^{*}\Big|\sum u(k)\chi(k)\Big|^2
\ \ll\ \Big(\frac{N}{H}+Q\Big)\,H\cdot \frac{N}{(\log N)^{A+10}}
\ \ll\ \frac{NQ}{(\log N)^{A}},
$$

since $\frac{N}{H}\asymp Q\,N^{\varepsilon}$. $\Box$

*Remarks.*

* The primitive/all-characters choice only improves the bound.
* Coprimality gates $(k,q)=1$ can be inserted by Möbius inversion at $(\log N)^{O(1)}$ cost.
* Smoothing losses are absorbed in the $+10$ log-headroom.


\section*{3. Lemma 3.2 (BV with parity, second moment)}
Fix $A>0$. Then there is $B=B(A)$ such that for all large $N$ and

$$
Q\ \le\ N^{1/2}\,(\log N)^{-B},
$$

every coefficient family $c_n$ supported on $n\asymp N$ with a Type-I/II decomposition and divisor bounds (as in your draft) satisfies

$$
\sum_{q\le Q}\ \sum_{\chi\bmod q}
\Bigg|\sum_{n} c_n\,\lambda(n)\,\chi(n)\Bigg|^2
\ \ll_{A}\ \frac{NQ}{(\log N)^A}.
$$

*Hypotheses (unchanged, recorded for reference).*
There exists $\psi\in C_c^\infty((1/2,2))$ with $c_n=\psi(n/N)\,d_n$, $|d_n|\le \tau_k(n)$ (fixed $k$), and either

* **Type I:** $d_n=\sum_{m\ell=n}\alpha_m\beta_\ell$ with $M\le N^{1/2-\eta}$, $|\alpha_m|\ll \tau_k(m)$, $|\beta_\ell|\ll \tau_k(\ell)$, or
* **Type II:** same but $N^{\eta}\le M\le N^{1/2-\eta}$.

*Proof.* Write

$$
S(\chi)=\sum_{n} c_n\,\lambda(n)\chi(n).
$$

Insert the Type-I/II structure, smooth in $m,\ell$ as in your draft, and set $L=N/M$. As you already arranged, Cauchy–Schwarz in $m$ reduces the problem to bounding, **uniformly in $m\sim M$**,

$$
\Sigma_m:=\sum_{q\le Q}\sum_{\chi\bmod q}\Big|\sum_{\ell\asymp L} b^{(m)}_\ell\,\lambda(\ell)\chi(\ell)\Big|^2,
$$

with $|b^{(m)}_\ell|\ll \tau_k(\ell)$ and a fixed smooth weight $\psi_m(\ell)=\psi(m\ell/N)$.

We split characters into **non-pretentious** and **exceptional** via the pretentious Halász dichotomy.

**(1) Non-pretentious block.**
By smooth Halász with divisor weights (standard, recorded in your draft), for any $C\ge 1$,

$$
\sum_{\ell\asymp L} b^{(m)}_\ell\,\lambda(\ell)\chi(\ell)\ \ll_k\ L(\log L)^{-C}
\qquad(\chi\notin\mathcal E(L;C)).
$$

Hence

$$
\sum_{q\le Q}\sum_{\substack{\chi\bmod q\\ \chi\notin\mathcal E(L;C)}}
\Big|\sum_{\ell\asymp L}\cdots\Big|^2\ \ll\ Q^2 L^2 (\log N)^{-2C}.
$$

**(2) Exceptional block.**
Let $\mathcal E_{\le Q}(L;C)=\bigcup_{q\le Q}\{\chi\bmod q:\chi\in\mathcal E(L;C)\}$. By a **log-free zero-density bound** (Gallagher–Montgomery–Vaughan style) in its pretentious formulation, for any $C_1$ there is $C_2=C_2(C_1)$ with

$$
\#\mathcal E_{\le Q}(L;C_1)\ \ll\ Q\,(\log (QL))^{-C_2},
$$

uniformly for $Q\le L^{1/2}(\log L)^{-100}$, which our choice of $Q$ ensures (since $L\ge N^{\eta}$). For each exceptional $\chi$,

$$
\Big|\sum_{\ell\asymp L} b^{(m)}_\ell\,\lambda(\ell)\chi(\ell)\Big|
\ \ll_k\ L(\log N)^{O(1)}.
$$

Therefore their total contribution is

$$
\ll\ Q\cdot L^2 (\log N)^{-C_2+O(1)}.
$$

**(3) Combine and reinsert $m$.**
Thus, for each $m$,

$$
\Sigma_m\ \ll\ Q^2 L^2 (\log N)^{-2C} \ +\ Q L^2 (\log N)^{-C_2+O(1)}.
$$

Multiply by $\sum_{m\sim M}|\alpha_m\lambda(m)|^2\ll M(\log N)^{O(1)}$ (from divisor bounds), use $ML=N$, and take $C$ and then $C_2$ large in terms of $A,k,\eta$. This yields

$$
\sum_{q\le Q}\sum_{\chi}|S(\chi)|^2\ \ll\ \frac{NQ}{(\log N)^A}.
$$

Finally, sum over $O((\log N)^C)$ dyadic partitions used to build $c_n$; absorbing this by increasing $A$ gives the stated bound. $\Box$

*Notes for the reader (won’t appear in the paper):*

* The only place the $Q$-range matters is ensuring $Q\le L^{1/2}(\log L)^{-100}$ to apply the log-free zero-density count; with $L\ge N^{\eta}$ and $Q\le N^{1/2}(\log N)^{-B}$, pick $B$ large in terms of $A,\eta$.
* A single possible Siegel character contributes $\ll Q L^2 e^{-c\sqrt{\log L}}$, which is negligible vs. $NQ/(\log N)^A$.


\part*{Part C. Type III Analysis}

\section*{4. Lemma S2.4 (Prime-averaged short-shift gain)}
We keep the notation from §4: $X\ge 3$, $0<\kappa<\tfrac14$, $Q\le X^{1/2-\kappa}$, a dyadic set $\mathcal Q\subset[Q,2Q]$ of moduli, primes $\mathcal P=\{p\in[P,2P]\}$ with $P=X^\vartheta$, $0<\vartheta<\tfrac16-\kappa$, and complex coefficients $|\alpha_p|\le 1$. For each $f$ in an orthonormal Hecke basis (holomorphic or Maaß of any weight, including oldforms, plus the Eisenstein family), define the prime amplifier

$$
\mathrm{Amp}(f)=\sum_{p\in\mathcal P}\alpha_p\,\lambda_f(p).
$$

Let $h_Q(t)=h(t/Q)$ with a fixed even $h\in C_c^\infty([-2,2])$, $h(0)=1$. For each $q\in\mathcal Q$ apply the Kuznetsov formula at level $q$ with spectral test $h_Q$. By the **Kernel Localization Lemma** (4.S.1 below), the geometric kernel $\mathcal W_q(z)$ satisfies

$$
\mathcal W_q(z),\ z\partial_z^{\,j}\mathcal W_q(z)\ \ll_{A,j}\Big(1+\frac zQ\Big)^{-A}\qquad(\forall A,j\ge0),
$$

uniformly across spectral families and all $q$. Writing $z=\frac{4\pi\sqrt{mn}}{c}$ shows the $c$-sum is supported on $c\asymp C:=X^{1/2}/Q$ with derivative control; we parameterize $c=qr$ so $r\asymp R:=C/q\asymp X^{1/2}/Q^2$.

We prove:

> **Lemma S2.4 (completed).**
> With the hypotheses above, for any $\varepsilon>0$,
>
> $$
> \mathrm{OD}\ \ \ll_{\varepsilon}\ (Q^2+X)^{1-\delta}\,|\mathcal P|^{\,2-\delta}\,X^{\varepsilon},
> $$
>
> where one may take
>
> $$
> \boxed{\ \ \delta\ =\ \frac1{1000}\,\min\!\Big\{\kappa,\ \tfrac12-3\vartheta\Big\}\ .\ }
> $$
>
> The bound holds uniformly in $\{\alpha_p\}$, and after summing holomorphic, Maaß (new+old), and Eisenstein contributions.

We split the proof into five steps.

\subsection*{Step 1. Balanced amplifier (deterministic signs)}

Let $\{\varepsilon_p\}_{p\in\mathcal P}\subset\{\pm1\}$ be a sequence with

$$
\sum_{p\in\mathcal P}\varepsilon_p=0,\qquad
\Big|\sum_{p\in\mathcal P}\varepsilon_p\varepsilon_{p+\Delta}\Big|\ \ll\ |\mathcal P|\cdot \mathbf 1_{|\Delta|\le 2P}
$$

(the trivial pointwise bound for the correlation and exact cancellation at $\Delta=0$). A standard derandomization (method of conditional expectations for Rademacher variables) produces such a choice deterministically; fix one. Define

$$
A_f=\sum_{p\in\mathcal P}\varepsilon_p\,\lambda_f(p).
$$

Then for any complex $S_f$,

$$
\sum_f |S_f|^2
\ \le\ \frac1{|\mathcal P|^2}\sum_f |A_f\,S_f|^2,
$$

by Cauchy–Schwarz after inserting $1=\big(\sum_p\varepsilon_p^2\big)/|\mathcal P|$ and expanding (the vanishing of $\sum_p\varepsilon_p$ kills the diagonal $p=p'$ in the amplifier square). We will apply this with

$$
S_{q,\chi,f}=\sum_{n\asymp X}\alpha_n\,\lambda_f(n)\,\chi(n),
$$

where $\{\alpha_n\}$ is the Type–III coefficient block (divisor-bounded, smooth).

\subsection*{Step 2. Hecke relations and removal of the “$n/p$” tail}

Opening $|A_f S_{q,\chi,f}|^2$ and using Hecke multiplicativity,

$$
\lambda_f(p)\lambda_f(n)=
\begin{cases}
\lambda_f(pn) & (p\nmid n),\\
\lambda_f(pn)-\lambda_f(n/p) & (p\mid n),
\end{cases}
$$

we may write the amplified second moment as a finite linear combination of terms with Hecke arguments $pn$ (and possibly $n/p$). Because the Type–III support is smooth and confined to $n\asymp X$, the contribution of the $n/p$ branch is supported on $n\asymp X$ with the extra condition $p\mid n$; by smooth partition and partial summation this piece is bounded by the same off-diagonal analysis (it is in fact easier since it has an extra divisibility). We henceforth treat explicitly the $pn$ branch; all others are dominated in the same way and absorbed into the final implied constant.

\subsection*{Step 3. Kuznetsov and off-diagonal reorganization}

Summing over $(q,\chi,f)$ with $q\in\mathcal Q$ and primitive $\chi\pmod q$, and applying Kuznetsov with test $h_Q$ at level $q$, the **diagonal** terms vanish by $\sum_p\varepsilon_p=0$. The **off-diagonal** geometric side takes the model form

$$
\mathrm{OD}
=\sum_{q\in\mathcal Q}\ \sum_{c\equiv 0\ (q)} \frac{1}{c}\!
\sum_{\substack{p_1,p_2\in\mathcal P\\ p_1\ne p_2}}\!
\sum_{m\asymp X} \alpha_m\overline{\alpha_{m'}}\,
S(m_{p_1},m'_{p_2};c)\,
\mathcal W_q\!\Big(\frac{4\pi\sqrt{m_{p_1}m'_{p_2}}}{c}\Big)\,
\varepsilon_{p_1}\varepsilon_{p_2},
$$

with $m_{p}=pm$ (suppressing the harmless $\chi$-twist which disappears on the geometric side). By the **Kernel Localization Lemma**, we may restrict to $c\in[C/2,2C]$, $C:=X^{1/2}/Q$, and write $c=qr$ with $r\asymp R:=X^{1/2}/Q^2$. Grouping by the short prime shift $\Delta:=p_1-p_2$ and introducing the pair-count

$$
\nu(\Delta)=\#\{(p_1,p_2)\in\mathcal P^2:\ p_1-p_2=\Delta,\ p_1\ne p_2\},
$$

we reorganize

$$
\mathrm{OD}
=\sum_{q\in\mathcal Q}\ \sum_{r\asymp R} \frac{1}{qr}
\sum_{\Delta\ne 0}\ \nu(\Delta)\ \Sigma_{q,r}(\Delta),
$$

where, for a smooth weight $W_{q,r}$ (absorbing $\alpha_m$ and the Bessel kernel),

$$
\Sigma_{q,r}(\Delta)=\sum_{m\asymp X} S(m,m+\Delta;qr)\,W_{q,r}(m,\Delta),
\qquad m\mapsto W_{q,r}\ \text{is }X\text{-smooth,\ } \Delta\mapsto W_{q,r}\ \text{is }P\text{-smooth}.
$$

All derivative bounds depend only on finitely many derivatives of $h$ and the smoothness of $\{\alpha_n\}$, hence are **uniform** in $q,r$.

---

\subsection*{Step 4. $\Delta$-second moment and harvesting the prime}average

By Cauchy–Schwarz in $\Delta$, the trivial bound $\nu(\Delta)\le |\mathcal P|$, and the **Short-shift $\Delta$-Second-Moment Lemma**, we have

$$
\sum_{|\Delta|\le P}\nu(\Delta)\,|\Sigma_{q,r}(\Delta)|
\ \le\ |\mathcal P|^{1/2}\,\Big(\sum_{|\Delta|\le P}\nu(\Delta)\Big)^{1/2}
\Big(\sum_{|\Delta|\le P}|\Sigma_{q,r}(\Delta)|^2\Big)^{1/2}
$$

$$
\ll_\varepsilon\ |\mathcal P|\,(P+qr)^{1/2}\,(qr)^{1/2+\varepsilon}\,X^{1/2+\varepsilon}.
$$

Hence, for each $q$,

$$
\sum_{r\asymp R}\frac{1}{qr}\sum_{\Delta}\nu(\Delta)\,\Sigma_{q,r}(\Delta)
\ \ll_\varepsilon\ |\mathcal P|\,q^{-1/2+\varepsilon}\,X^{1/2+\varepsilon}\,
\sum_{r\asymp R} r^{-1/2+\varepsilon}(P+qr)^{1/2}.
$$

On the support $r\asymp R$ we have $qr\asymp C=X^{1/2}/Q$, thus $(P+qr)^{1/2}$ is independent of $r$ (up to constants), and $\sum_{r\asymp R} r^{-1/2+\varepsilon}\asymp R^{1/2+\varepsilon}$. Using $q^{-1/2}R^{1/2}\asymp Q^{-1}$ gives

$$
\sum_{r}\cdots\ \ll_\varepsilon\ |\mathcal P|\,Q^{1+\varepsilon}\,\big(P+X^{1/2}/Q\big)^{1/2}.
$$

Summing $q\in\mathcal Q$ (there are $O(Q)$ moduli) yields the **conductor bound**

\begin{equation}
\boxed{\ \ \mathrm{OD}\ \ll_\varepsilon\ |\mathcal P|\,Q^{2+\varepsilon}\,\big(P+X^{1/2}/Q\big)^{1/2}. \ \ }
\tag{4.S.X}
\end{equation}

This is the only place where Bessel tails, oldforms, and Eisenstein matter; all are covered by the kernel lemma, which is uniform across spectral families (the proof for each family has the same derivative-decay structure).

---

\subsection*{Step 5. Regime balance and choice of $\delta$}

We rewrite $(4.S.\!\star)$ in the desired $(Q^2+X)^{1-\delta}|\mathcal P|^{2-\delta}$ form by splitting into the two natural regimes, using $Q\le X^{1/2-\kappa}$ and $|\mathcal P|\asymp P/\log P=X^{\vartheta+o(1)}$.

* **Regime I ($Q^2\ge X$).** Then $X^{1/2}/Q\le Q$, hence $(P+X^{1/2}/Q)^{1/2}\ll P^{1/2}+Q^{1/2}\ll Q^{1/2}$ because $P=X^\vartheta\le X^{1/6-\kappa}\le Q^{1/3}$. Thus

  $$
  \mathrm{OD}\ \ll_\varepsilon\ |\mathcal P|\,Q^{5/2+\varepsilon}.
  $$

  We want $\mathrm{OD}\ll (Q^2)^{1-\delta}\,|\mathcal P|^{2-\delta}$, i.e.

  $$
  |\mathcal P|\,Q^{5/2}\ \ll\ Q^{2-2\delta}\,|\mathcal P|^{\,2-\delta}.
  $$

  Rearranged, $Q^{1/2+2\delta}\ll |\mathcal P|^{\,1-\delta}$. Using $Q\asymp X^{1/2}$ in this regime and $|\mathcal P|\asymp X^\vartheta$, this is implied by

  $$
  \tfrac14+\delta\ \le\ \vartheta(1-\delta).
  $$

  This holds once $\delta\le \tfrac12-3\vartheta$ (take a small fraction to cover constants).

* **Regime II ($Q^2\le X$).** Then $X^{1/2}/Q\ge X^\kappa$, so

  $$
  \mathrm{OD}\ \ll_\varepsilon\ |\mathcal P|\,Q^{2+\varepsilon}\,X^{\max\{\vartheta,\kappa\}/2}
  \ \le\ |\mathcal P|\,X^{1-2\kappa+\varepsilon}\,X^{\max\{\vartheta,\kappa\}/2}.
  $$

  We want $\mathrm{OD}\ll X^{1-\delta}\,|\mathcal P|^{\,2-\delta}$. With $|\mathcal P|\asymp X^\vartheta$ this reduces to

  $$
  -\vartheta(1-\delta)\ \le\ -\delta + \tfrac32\kappa - \tfrac{(\vartheta-\kappa)_+}{2}.
  $$

  This is satisfied provided

  $$
  \delta\ \le\ \min\Big\{\ \kappa,\ \tfrac12-3\vartheta\ \Big\}
  $$

  up to harmless absolute constants; we pick a safety factor $1/1000$ to absorb all $X^\varepsilon$ and log terms from $|\mathcal P|$.

Choosing

$$
\delta=\frac1{1000}\min\{\kappa,\tfrac12-3\vartheta\}
$$

meets both regimes, and plugging back $|\mathcal P|=X^{\vartheta+o(1)}$ absorbs the $|\mathcal P|^{-\delta}$ factor into $X^\varepsilon$, yielding the claimed bound.

$\square$

\subsection*{4.S.1. Kernel localization (stated for completeness)}

**Lemma (uniform kernels).**
Let $h\in C_c^\infty([-2,2])$ be even with $h(0)=1$, $h_Q(t)=h(t/Q)$. For each spectral family (holomorphic, Maaß, Eisenstein) at level $q$, let $\mathcal W_q$ be the geometric kernel in Kuznetsov associated to $h_Q$. Then for all $A,j\ge0$,

$$
\mathcal W_q(z)\ \ll_A\Big(1+\frac zQ\Big)^{-A},\qquad
z\,\partial_z^{\,j}\mathcal W_q(z)\ \ll_{A,j}\Big(1+\frac zQ\Big)^{-A},
$$

uniformly in $q\ge 1$ and across families. In particular the $c$-sum is restricted to $c\asymp X^{1/2}/Q$ (with tails $O_A(X^{-A})$).

*Sketch.* Scale in the Hankel transforms and integrate by parts in Mellin; the level $q$ does not enter the transform—only the congruence $c\equiv 0\pmod q$ on the geometric side—so bounds are uniform in $q$.

\subsection*{4.S.2. Remarks on oldforms and Eisenstein}

The Kuznetsov decomposition splits into holomorphic, Maaß new/old, and Eisenstein. Each contributes the same Kloosterman structure with its own kernel $\mathcal W_q^{(*)}$ obeying the same decay/derivative bounds (the proofs for $J$- and $K$-transforms are identical after scaling). Our use of the $\Delta$-second-moment lemma and Weil’s bound is completely **family-agnostic**, so the sum over all families only changes the implied constant.

\subsection*{4.S.3. Parameters at a glance}

* Minor-arc cut: $Q\le X^{1/2-\kappa}$.
* Amplifier length: $P=X^\vartheta$ with $0<\vartheta<\tfrac16-\kappa$.
* Resulting saving: $\delta=\frac1{1000}\min\{\kappa,\tfrac12-3\vartheta\}$.
* Recommended choice later in Part C.5/D.6: fix any small $\vartheta\le \kappa/4$, then $\delta\gg\vartheta$; the factor $|\mathcal P|^{-\delta}=X^{-\vartheta\delta}$ is absorbed into $X^\varepsilon$.

With S2.4 now fully explicit and uniform, you can plug it straight into **Part C.5 (Type-III spectral second moment)** and then the **Assembly/Dyadic step (Part D.6)** exactly as drafted. If you want, next I can tighten **Lemma 3.2 / Route-B** into a line-by-line proof (pretentious Halász + log-free density + hybrid large sieve) so Part B is truly “camera-ready.”


\section*{5. Type-III Spectral Bound}

**Proposition (Type-III spectral second moment).**
Let $(\alpha_n)$ be a smooth Type-III coefficient sequence supported on $n\asymp X$, with divisor-type bounds $|\alpha_n|\ll_\varepsilon \tau(n)^C$ and smooth weight of width $X^{1+o(1)}$. For $Q\ge 1$, let the outer sums range over moduli $q\le Q$, primitive characters $\chi\pmod q$, and an orthonormal Hecke basis $f$ (holomorphic + Maaß, including oldforms and Eisenstein as in Kuznetsov). Assume **Lemma S2.4 (Prime-averaged short-shift gain)** holds with some fixed $\delta>0$. Then, for any $\varepsilon>0$,

$$
\sum_{q\le Q}\ \sum_{\chi\ (\mathrm{mod}\ q)}\ \sum_{f}
\Bigg|\sum_{n\asymp X}\alpha_n\,\lambda_f(n)\chi(n)\Bigg|^2
\ \ \ll_{\varepsilon,C}\ \ (Q^2+X)^{\,1-\delta}\,X^{\varepsilon}.
$$

\subsection*{Proof (using Lemma S2.4)}

\subsection*{Step 1: Balanced prime amplifier that kills the diagonal.}
Let $\mathcal P$ be the set of primes $p\in[P,2P]$ with $P=X^\vartheta$ (to be chosen; Lemma S2.4 is uniform in $P$).
Choose deterministic signs $\varepsilon_p\in\{\pm 1\}$ so that

$$
\sum_{p\in\mathcal P}\varepsilon_p=0
\qquad\text{and}\qquad
\Big|\sum_{p\in\mathcal P}\varepsilon_p\varepsilon_{p+\Delta}\Big|\ \ll\ |\mathcal P|\cdot \mathbf{1}_{|\Delta|\le P^{1-o(1)}},
$$

i.e. a “balanced Rademacher” choice; a random choice satisfies this with probability $\gg 1$, and we fix one such choice.

Define the amplifier on the spectrum:

$$
A_f \ :=\ \sum_{p\in\mathcal P}\varepsilon_p\,\lambda_f(p).
$$

Because $\sum_p\varepsilon_p=0$, expanding $|A_f|^2$ removes the pure diagonal $p=p'$ on average over signs, leaving only short prime shifts $p\neq p'$ with $\Delta = p-p'$ (the “short-shift” structure needed for Lemma S2.4).

\subsection*{Step 2: Diagonal-free reduction by polarization.}
For any complex numbers $S_f$,

$$
\sum_f |S_f|^2
=\frac{1}{\sum_{p\in\mathcal P}\varepsilon_p^2}\,
\sum_f |S_f|^2\cdot \Big(\sum_{p\in\mathcal P}\varepsilon_p^2\Big)
=\frac{1}{|\mathcal P|}\sum_f |S_f|^2\cdot \sum_{p\in\mathcal P}1.
$$

Insert $1=\frac{1}{|\mathcal P|}\sum_{p\in\mathcal P}\varepsilon_p^2$ and then *complete the square* with $A_f$:

$$
\sum_f |S_f|^2
=\frac{1}{|\mathcal P|^2}\sum_f |S_f|^2\cdot \sum_{p,p'\in\mathcal P}\varepsilon_p\varepsilon_{p'}\,\lambda_f(p)\lambda_f(p')
\ \ \le\ \ \frac{1}{|\mathcal P|^2}\sum_f |A_f\,S_f|^2,
$$

where the inequality is Cauchy–Schwarz in $\sum_{p,p'}$ (this is the standard “balanced-amplifier domination”: the diagonal $p=p'$ having zero mean is what prevents a trivial loss).

Apply this with

$$
S_{q,\chi,f}\ :=\ \sum_{n\asymp X}\alpha_n\,\lambda_f(n)\chi(n).
$$

Summing over $q\le Q,\chi$ gives

\begin{equation}
\sum_{q\le Q}\sum_{\chi}\sum_f |S_{q,\chi,f}|^2
\ \ \le\ \ \frac{1}{|\mathcal P|^2}\,
\sum_{q\le Q}\sum_{\chi}\sum_f \big|A_f\,S_{q,\chi,f}\big|^2.
\tag{3.1}
\end{equation}

\subsection*{Step 3: Kuznetsov after opening the amplifier.}
Open $|A_f S_{q,\chi,f}|^2$ and use Hecke relations to rewrite prime factors $\lambda_f(p)\lambda_f(n)$ as a (short) combination of $\lambda_f(pn)$ and $\lambda_f(n/p)$ (the latter is discarded as $p\nmid n$ for Type-III supports). After summing over $(q,\chi,f)$ and applying Kuznetsov (including oldforms + Eisenstein), the contribution splits into:

\begin{itemize}
\item **Short-shift off-diagonal (OD):** correlations of the form
  $\sum_{p\neq p'\in\mathcal P}\varepsilon_p\varepsilon_{p'}\sum_{m,n\asymp X}\alpha_m\overline{\alpha_n}\, \mathcal{K}_{q}(m, n; p-p')$,
  with Kloosterman sums $S(m,n;cq)$ and Bessel kernels;
\item **(Spectral) diagonal/main terms:** the parts that would arise from $p=p'$ or $\Delta=0$, but these are *annihilated* by $\sum_p\varepsilon_p=0$ and by our balanced-sign choice, leaving at most lower-order boundary terms absorbed in $X^{\varepsilon}$.
\end{itemize}

Precisely this OD piece is what **Lemma S2.4** estimates *after* the amplifier and Kuznetsov:

> **Lemma S2.4 (assumed).** Uniformly in $P=X^\vartheta$,
>
> $$
> \mathrm{OD}\ \ \ll\ \ (Q^2+X)^{1-\delta}\,|\mathcal P|^{\,2-\delta}\,X^{\varepsilon}.
> $$

All Bessel-kernel ranges (small/large) are handled there; Weil bounds for $S(\cdot,\cdot;\cdot)$, the $c\equiv0\pmod q$ constraint, oldforms and Eisenstein, and the short-shift averaging in $\Delta$ are already accounted for in the statement of S2.4.

Therefore,

\begin{equation}
\sum_{q\le Q}\sum_{\chi}\sum_f \big|A_f\,S_{q,\chi,f}\big|^2
\ \ \ll\ \ (Q^2+X)^{1-\delta}\,|\mathcal P|^{\,2-\delta}\,X^{\varepsilon}.
\tag{3.2}
\end{equation}


\subsection*{Step 4: Divide out the amplifier and optimize $P$.}
Insert (3.2) into (3.1):

$$
\sum_{q\le Q}\sum_{\chi}\sum_f |S_{q,\chi,f}|^2
\ \ \ll\ \ \frac{1}{|\mathcal P|^2}\ (Q^2+X)^{1-\delta}\,|\mathcal P|^{\,2-\delta}\,X^{\varepsilon}
\ =\ (Q^2+X)^{1-\delta}\,|\mathcal P|^{-\delta}\,X^{\varepsilon}.
$$

Choose any fixed $\vartheta>0$ (e.g. $\vartheta=\delta/4$) so that $|\mathcal P|=P/\log P=X^{\vartheta+o(1)}$ and absorb $|\mathcal P|^{-\delta}=X^{-\vartheta\delta+o(1)}$ into $X^{\varepsilon}$ (by shrinking $\varepsilon$). This yields

$$
\sum_{q\le Q}\sum_{\chi}\sum_f \Big|\sum_{n\asymp X}\alpha_n\,\lambda_f(n)\chi(n)\Big|^2
\ \ \ll\ \ (Q^2+X)^{1-\delta}\,X^{\varepsilon},
$$

as claimed. $\square$

\subsection*{Remarks}

\begin{itemize}
\item **Uniformity \& hypotheses.** The argument only used (i) Type-III structure (smooth $\alpha_n$, divisor bounds), (ii) balanced prime amplifier with $\sum \varepsilon_p=0$, (iii) Kuznetsov with full continuous and oldform ranges, and (iv) Lemma S2.4’s OD estimate. No further spectral gap input is needed beyond what S2.4 encapsulates.

\item **Why the diagonal doesn’t spoil the saving.** The balanced amplifier removes the dangerous $p=p'$ contribution *before* applying Kuznetsov. What remains are genuinely shifted correlations $(\Delta\neq 0)$, to which S2.4 applies and gives the $(Q^2+X)^{1-\delta}$ saving.

\item **Choice of $\vartheta$.** Any fixed $\vartheta\in(0,1/2)$ permitted by S2.4 works; the $|\mathcal P|^{-\delta}$ factor improves the exponent, and we simply absorb it into $X^{\varepsilon}$.
\end{itemize}

This completes Part C.5 once Lemma S2.4 is rigorously in place.

great — here’s a clean, self-contained “finish” for Part D.6 that plugs in the previously established Type I/II and Type III inputs, carries the dyadic bookkeeping, and arrives at the stated minor-arc $L^2$ bound.

---

\part*{Part D. Assembly}

\section*{6. Dyadic Decomposition (final)}

\subsection*{Statement D.6.}

Let $S(\alpha)=\sum_{n\le N}\Lambda(n)\,w(n)\,e(\alpha n)$ with a fixed smooth weight $w$ supported on $[N/2,2N]$ and let $B(\alpha)$ be the parity-blind majorant from Part A. For the minor arcs $\mathfrak m$ defined with denominator cutoff $Q=N^{1/2-\varepsilon}$, assume the analytic inputs:

\begin{itemize}
\item **(I/II)**: For any smooth Type-I/II coefficient structure $\{c_n\}$ with divisor bounds (arising from Vaughan/Heath–Brown), the second-moment Barban–Davenport–Halász–pretentious bound

\begin{equation}
\sum_{q\le Q}\ \sum_{\chi\bmod q}\Big|\sum_{n\le N} c_n\,\lambda(n)\chi(n)\Big|^2
\ \ll\ \frac{NQ}{(\log N)^A}
\tag{D.1}
\end{equation}

holds for each fixed $A>0$. (This is Lemma 3.2 and the “Route B Lemma” for the balanced ranges.)

\item **(III)**: For every dyadic Type-III block $\sum_{n\asymp X}\alpha_n\,\lambda_f(n)\chi(n)$ produced after amplification and Kuznetsov, the prime-averaged off-diagonal is bounded by

\begin{equation}
\mathrm{OD}\ \ll\ (Q^2+X)^{1-\delta}\,|\mathcal P|^{\,2-\delta}
\tag{D.2}
\end{equation}

for some fixed $\delta>0$, uniformly for amplifier length $|\mathcal P|=X^\vartheta$ with $\vartheta=\vartheta(\delta)>0$, and with uniform control of oldforms/Eisenstein and Bessel kernels. (This is Lemma S2.4 and its Type-III spectral corollary.)
\end{itemize}

Then, for any $\varepsilon>0$,

$$
\int_{\mathfrak m}\big|S(\alpha)-B(\alpha)\big|^2\,d\alpha
\ \ll\ \frac{N}{(\log N)^{3+\varepsilon}}.
$$

\subsection*{Proof.}

**Step 1: Identity and dyadic model.**
Apply a 3-, 4-, or 5-fold Heath–Brown identity (any standard version suffices) to $\Lambda$ with cut parameters

$$
U=N^{\mu},\quad V=N^{\nu},\quad W=N^{\omega},\qquad 0<\mu\le\nu\le\omega<1,
$$

chosen below. We write

$$
S(\alpha)-B(\alpha)
=\sum_{\text{HB terms }\mathcal T} \mathcal S_{\mathcal T}(\alpha),
$$

where each $\mathcal S_{\mathcal T}$ is a finite linear combination (with coefficients having $\ll_\epsilon n^\epsilon$ divisor bounds and smooth dyadic cutoffs) of exponential sums of one of the three structural types:

* **Type I**: $\displaystyle \sum_{m\asymp M} a_m \sum_{n\asymp N/M} b_n\,e(\alpha mn)$ with $M\le U$ (or the dual small variable),
* **Type II**: balanced $\displaystyle \sum_{m\asymp M}\sum_{n\asymp N/M} a_m b_n\,e(\alpha mn)$ with $U\ll M\ll N/U$,
* **Type III**: “ternary” or highly factorized pieces with all variables in ranges $ \ll N^{1/3+o(1)}$, which, after the amplifier/Kuznetsov transition, become prime-averaged short-shift sums against automorphic coefficients.

All sums are partitioned into **$O((\log N)^C)$** dyadic blocks in all active variables for some fixed $C$.

**Step 2: Minor-arc $L^2$ via large sieve on dyadics.**
Let $\mathfrak M(q,a)$ be the standard major arc around $a/q$ with width $\asymp (qQ)^{-1}$, and set $\mathfrak m=[0,1]\setminus \bigcup_{q\le Q}\bigcup_{(a,q)=1}\mathfrak M(q,a)$. On $\mathfrak m$ we use the standard large-sieve/dispersion reduction:

\begin{equation}
\int_{\mathfrak m} \big|\mathcal S_{\mathcal T}(\alpha)\big|^2\,d\alpha
\ \ll\ \frac{1}{Q^2}\sum_{q\le Q}\sum_{\substack{a\bmod q\\(a,q)=1}}
\left|\sum_{n} c_n\,e\!\left(\frac{an}{q}\right)\right|^2,
\tag{D.3}
\end{equation}

for suitable coefficients $c_n$ associated to the dyadic block $\mathcal T$. By opening the square and expanding in Dirichlet characters modulo $q$, (D.3) reduces to sums of the form

\begin{equation}
\sum_{q\le Q}\ \sum_{\chi\bmod q}
\Big|\sum_{n\asymp X} c_n\,\lambda(n)\chi(n)\Big|^2,
\tag{D.4}
\end{equation}

or, in the Type-III case after the amplifier/Kuznetsov step, to a spectral second moment whose diagonal/off-diagonal split is controlled by (D.2).

We now bound (D.4) block-wise and then sum the dyadics.


\subsection*{Step 3: Type I/II dyadics.}
Choose $U=N^{1/3}$ (any $\mu\in(1/4,1/2)$ is fine) so that all Type I/II ranges from the chosen Heath–Brown identity fall either in the “small–large” or “balanced” regimes. By the input (I/II), for any $A>0$,

$$
\sum_{q\le Q}\sum_{\chi\bmod q}
\Big|\sum_{n\le N} c_n\,\lambda(n)\chi(n)\Big|^2
\ \ll\ \frac{NQ}{(\log N)^A}.
$$

Each Type I or Type II dyadic contributes $\ll NQ/(\log N)^A$. There are $\ll(\log N)^C$ such dyadics in total, so by taking $A\ge 3+C+10\varepsilon^{-1}$ we obtain

\begin{equation}
\sum_{\text{Type I/II dyadics}}
\int_{\mathfrak m}\big|\mathcal S_{\mathcal T}(\alpha)\big|^2 d\alpha
\ \ll\ \frac{N}{(\log N)^{3+\varepsilon}}.
\tag{D.5}
\end{equation}

\subsection*{Step 4: Type III dyadics.}
Fix $V=W=N^{1/3}$ so that the residual blocks with all variables $\ll N^{1/3+o(1)}$ are designated Type III. For such a block, let its “outer scale” be $X\asymp N^\xi$ with $\xi\in(0,1)$ determined by the product of the active variables. After applying the amplifier of length $|\mathcal P|=X^\vartheta$ and Kuznetsov, we face a spectral second moment whose off-diagonal obeys (D.2):

$$
\mathrm{OD}\ \ll\ (Q^2+X)^{1-\delta}\,|\mathcal P|^{\,2-\delta}
\ =\ (Q^2+X)^{1-\delta}\,X^{\vartheta(2-\delta)}.
$$

Take $\vartheta=\tfrac{\delta}{8}$ (any fixed small choice depending on $\delta$ works). Since $Q=N^{1/2-\varepsilon}$, we have $Q^2=N^{1-2\varepsilon}$. Two regimes:

* If $X\le Q^2$ then $\mathrm{OD}\ll N^{(1-2\varepsilon)(1-\delta)}\,X^{\vartheta(2-\delta)}$.
* If $X\ge Q^2$ then $\mathrm{OD}\ll X^{1-\delta+\vartheta(2-\delta)}$.

In both cases there is a fixed saving $X^{-\eta}$ (or $N^{-\eta}$) for some $\eta=\eta(\delta,\vartheta,\varepsilon)>0$ against the trivial diagonal scale, after the standard dispersion normalization. Consequently each Type III dyadic contributes

\begin{equation}
\int_{\mathfrak m}\big|\mathcal S_{\mathcal T}(\alpha)\big|^2 d\alpha
\ \ll\ \frac{N}{(\log N)^{A}}\,X^{-\eta}
\ \ +\ \ \text{(diagonal)}.
\tag{D.6}
\end{equation}

The diagonal is controlled either by the amplifier normalization or by subtracting the parity-blind majorant $B(\alpha)$ (which removes the main term on $\mathfrak m$), leaving at most $\ll N/(\log N)^A$ per block. Summing (D.6) over the $\ll(\log N)^C$ Type-III dyadics and choosing $A$ large, we obtain

\begin{equation}
\sum_{\text{Type III dyadics}}
\int_{\mathfrak m}\big|\mathcal S_{\mathcal T}(\alpha)\big|^2 d\alpha
\ \ll\ \frac{N}{(\log N)^{3+\varepsilon}}.
\tag{D.7}
\end{equation}

*Bookkeeping note.* The $X^{-\eta}$ saving is uniform in the dyadic location because $\delta>0$ is fixed and $\vartheta$ is chosen as a fixed fraction of $\delta$; any residual factors from Bessel kernels, oldforms, and Eisenstein are already absorbed in (D.2) by the uniform spectral analysis ensured in Lemma S2.4. The $q$-sum restriction $q\le Q$ matches the circle-method minor-arc decomposition, so no leakage arises.

---

\subsection*{Step 5: Conclusion.}
Adding (D.5) and (D.7) over all dyadics of all HB terms $\mathcal T$ yields

$$
\int_{\mathfrak m}\big|S(\alpha)-B(\alpha)\big|^2 d\alpha
\ \ll\ \frac{N}{(\log N)^{3+\varepsilon}},
$$

as claimed.

$\square$

\subsection*{Parameter choices \& loss ledger (for ease of cross-checking)}

\begin{itemize}
\item **Minor-arc cutoff**: $Q=N^{1/2-\varepsilon}$.
\item **HB cut parameters**: $U=V=W=N^{1/3}$ (any fixed exponents in $(1/4,1/2)$ that produce the standard Type I/II/III taxonomy will do).
\item **Amplifier**: primes of length $|\mathcal P|=X^\vartheta$ with $\vartheta=\delta/8$.
\item **Savings**:

  * Large-sieve minor-arc reduction costs a factor $\asymp Q^{-2}$ which is recovered in (D.1)/(D.2).
  * Type I/II: pick $A$ so that $(\log N)^C$ dyadic inflation is dominated; we target $3+\varepsilon$ net powers of $\log$.
  * Type III: the $\delta$-saving from (D.2) after amplifier normalization yields uniform $X^{-\eta}$ decay, summable across dyadics.
\item **Exceptional characters / oldforms / Eisenstein**: already handled in the hypotheses of Lemma 3.2 and Lemma S2.4; their contributions obey the same $(\log N)^{-A}$ savings and therefore do not affect the sum.
\end{itemize}

\subsection*{Remark.}

Nothing delicate hinges on the exact form of the identity (Vaughan vs. Heath–Brown) provided it yields (i) divisor-bounded smooth coefficients and (ii) a genuine three-variable “Type III” regime where Lemma S2.4 applies. Alternative cut choices merely reshuffle a finite number of dyadic families and do not change the final $(\log N)^{-3-\varepsilon}$ power once $A$ is taken large in the Type I/II inputs.

here’s a clean write-up you can drop into your document.

---

\section*{7. Major–Arc Evaluation}

Let

$$
\mathfrak M=\bigcup_{\substack{1\le q\le Q\\(a,q)=1}}\mathfrak M(a,q),\qquad 
\mathfrak M(a,q):=\{\alpha\in[0,1):\ |\alpha-\tfrac aq|\le \tfrac{Q}{qN}\},
$$

with $Q=N^{1/2-\varepsilon}$. Write $\alpha=a/q+\beta$ on $\mathfrak M(a,q)$ and set

$$
V(\beta):=\sum_{n\le N}e(n\beta) \qquad\text{and}\qquad \widehat w(\beta):=\sum_{n}w(n)e(n\beta)
$$

for the sharp/smoothed Dirichlet kernels according to whether $S, B$ are unweighted or carry a fixed smooth weight $w$ supported on $[1,N]$ with $w^{(j)}\ll_j N^{-j}$.

We denote by $\mathfrak S(N)$ the (Goldbach) singular series

$$
\mathfrak S(N)=2\prod_{p\ge 3}\Big(1-\frac1{(p-1)^2}\Big)
\prod_{\substack{p\mid N\\ p\ge 3}}\frac{p-1}{p-2},
$$

and by $\mathfrak J$ the singular integral

$$
\mathfrak J=
\begin{cases}
\displaystyle \int_{-\infty}^{\infty}\Big|\frac{\sin(\pi N\beta)}{\sin(\pi\beta)}\Big|^{\!2}e(-N\beta)\,d\beta
&\text{(sharp cut-off)},\\[2ex]
\displaystyle \int_{-\infty}^{\infty}|\widehat w(\beta)|^{2}e(-N\beta)\,d\beta
&\text{(smooth cut-off)}.
\end{cases}
$$

Standard analysis yields $\mathfrak J=N+O(1)$ in the sharp case and $\mathfrak J=\widehat w(0)^2 N+O(1)$ in the smooth case.

We evaluate first the parity-blind majorant $B$, then transfer the main term to $S$.

\subsection*{7.1. Major–arc evaluation for $B(\alpha)$.}

Let the sieve majorant be

$$
B(\alpha)=\sum_{n\le N}\beta(n)\,e(n\alpha),\qquad 
\beta=\beta_{z,D}\ \text{a linear (Rosser–Iwaniec) weight of level }D=N^{1/2-\varepsilon},
$$

so that $\beta$ has the standard divisor-bounded structure

$$
\beta(n)=\sum_{\substack{d\mid n\\ d\mid P(z)}}\lambda_d,\qquad 
\lambda_d\ll_\varepsilon d^\varepsilon,\quad \sum_{d\mid P(z)}\frac{|\lambda_d|}{d}\ll \log z,
$$

with $P(z)=\prod_{p<z}p$ and $z=N^{\eta}$ a small fixed power.

On $\alpha=a/q+\beta$ with $q\le Q$ and $|\beta|\le Q/(qN)$, expand

$$
B(\alpha)=\sum_{d\mid P(z)}\lambda_d
\sum_{\substack{m\le N/d}} e\!\big(dm(\tfrac aq+\beta)\big)
=\sum_{d\mid P(z)}\lambda_d\, e\!\big(\tfrac{ad}{q}\big)\,V_d(\beta),
$$

where $V_d(\beta):=\sum_{m\le N/d}e(dm\beta)$. By the standard completion and the Euler product calculation for linear sieve weights (matching local factors for $p<z$), one obtains the **major–arc approximation**

$$
B(a/q+\beta)=\frac{\rho(q)}{\varphi(q)}\,V(\beta)\,+\,\mathcal E_B(q,\beta),
$$

where $\rho(q)$ is multiplicative, supported on square-free $q$, and satisfies

$$
\rho(p)=
\begin{cases}
-1& \text{for } p\ge 3,\\
0 & \text{for } p=2,
\end{cases}
\qquad\text{so that}\quad \frac{\rho(q)}{\varphi(q)}=\frac{\mu(q)}{\varphi(q)}
$$

for all odd $q$ with $p<z$ local factors correctly matched. Moreover, uniformly for $q\le Q$ and $|\beta|\le Q/(qN)$,

$$
\mathcal E_B(q,\beta)\ \ll\ N(\log N)^{-A}
$$

for any fixed $A>0$ once $z=N^\eta$ and $D=N^{1/2-\varepsilon}$ are tied as usual (this is the standard “well-factorable” savings of the linear sieve on major arcs).

Squaring and integrating over $\mathfrak M$ (disjoint up to negligible overlaps) gives

$$
\int_{\mathfrak M} B(\alpha)^2 e(-N\alpha)\,d\alpha
= \sum_{q\le Q}\ \sum_{\substack{a\bmod q\\(a,q)=1}}
\int_{|\beta|\le Q/(qN)} 
\Big(\frac{\mu(q)}{\varphi(q)}V(\beta)\Big)^{\!2} e(-N\beta)\,d\beta
\ +\ O\!\Big(\frac{N}{(\log N)^{3+\varepsilon}}\Big),
$$

where the error uses Cauchy–Schwarz with $\int_{\mathfrak M}|V(\beta)|^2 d\beta\ll N\log N$, the uniform bound on $\mathcal E_B$, and the total measure of $\mathfrak M$.
Since $\sum_{(a,q)=1}1=\varphi(q)$ and $\int_{|\beta|\le Q/(qN)}V(\beta)^2 e(-N\beta)\,d\beta=\mathfrak J+O(NQ^{-1})$,

$$
\int_{\mathfrak M} B(\alpha)^2 e(-N\alpha)\,d\alpha
= \Big(\sum_{q=1}^{\infty}\frac{\mu(q)^2}{\varphi(q)^2}\,c_q(N)\Big)\,\mathfrak J
\ +\ O\!\Big(\frac{N}{(\log N)^{3+\varepsilon}}\Big),
$$

with $c_q(N)$ the Ramanujan sum. The absolutely convergent series equals the Goldbach singular series $\mathfrak S(N)$. Hence

$$
\boxed{\ \ \int_{\mathfrak M} B(\alpha)^2 e(-N\alpha)\,d\alpha
=\mathfrak S(N)\,\mathfrak J\;+\;O\!\big(N(\log N)^{-3-\varepsilon}\big)\ .\ }
$$

*(Remark.)* If a smooth weight $w$ is used, replace $V(\beta)$ by $\widehat w(\beta)$ throughout, and the same argument yields $\mathfrak J=\int|\widehat w|^2 e(-N\beta)\,d\beta$ with an identical error term.

\subsection*{7.2. Transferring the main term to $S(\alpha)$.}

Let $S(\alpha)=\sum_{n\le N}\Lambda(n)\,e(n\alpha)$ (sharp or smooth as above). By the prime number theorem in arithmetic progressions with level of distribution $Q=N^{1/2-\varepsilon}$ (Siegel–Walfisz + Bombieri–Vinogradov in the smooth form used earlier), uniformly for $q\le Q$ and $|\beta|\le Q/(qN)$,

$$
S(a/q+\beta)=\frac{\mu(q)}{\varphi(q)}\,V(\beta) \;+\; \mathcal E_S(q,\beta),
\qquad \mathcal E_S(q,\beta)\ \ll\ N(\log N)^{-A}
$$

for any fixed $A>0$. Consequently, exactly the same computation as in §7.1 gives

$$
\int_{\mathfrak M} S(\alpha)^2 e(-N\alpha)\,d\alpha
=\mathfrak S(N)\,\mathfrak J\;+\;O\!\big(N(\log N)^{-3-\varepsilon}\big).
$$

There are two convenient “comparison” routes:

* **Pointwise on $\mathfrak M$:** From the two approximations above,

  $$
  S(\alpha)-B(\alpha)=\mathcal E_S(\alpha)-\mathcal E_B(\alpha),
  $$

  whence $\int_{\mathfrak M}(S^2-B^2)e(-N\alpha)\,d\alpha =\int_{\mathfrak M}(S-B)(S+B)e(-N\alpha)\,d\alpha$
  is $\ll N(\log N)^{-A}$ after the same bookkeeping.

* **Integrated $L^2$ route:** Using the $L^2$ major-arc bounds $\int_{\mathfrak M}(|S|^2+|B|^2)\ll N\log N$, together with the pointwise major-arc approximants (or with your minor-arc $L^2$ control if you prefer to absorb overlaps), yields the same $O\big(N(\log N)^{-3-\varepsilon}\big)$ remainder for the difference of major-arc contributions.

Combining §7.1–§7.2 we conclude:

> **Proposition 7.1 (Major–arc main term).** For the major arcs $\mathfrak M$ with $Q=N^{1/2-\varepsilon}$,
>
> $$
> \int_{\mathfrak M} B(\alpha)^2 e(-N\alpha)\,d\alpha
> =\int_{\mathfrak M} S(\alpha)^2 e(-N\alpha)\,d\alpha
> =\mathfrak S(N)\,\mathfrak J\;+\;O\!\big(N(\log N)^{-3-\varepsilon}\big).
> $$
>
> In particular, $B$ and $S$ share the same Hardy–Littlewood main term on the major arcs, with an error that is negligible against $N(\log N)^{-2}$.

\subsection*{Status.} 
Everything here is standard Hardy–Littlewood major-arc analysis. What remains (and is already ensured by our earlier sections) is to (i) state the exact sieve parameters $(z,D)$ used to define $\beta$, and (ii) cite the precise Bombieri–Vinogradov/Siegel–Walfisz input in the smooth form employed so the uniform error $N(\log N)^{-A}$ on $\mathfrak M$ holds (both for $\Lambda$ and for the linear-sieve majorant).
here’s a clean, ready-to-drop-in write-up for your last step.

---

\section*{8. Final Step (conditional on (A.1))}

We now conclude the argument.

$$
R(N)\;=\;\int_0^1 S(\alpha)^2\,e(-N\alpha)\,d\alpha
\;=\;\int_{\mathfrak M} S(\alpha)^2 e(-N\alpha)\,d\alpha
\;+\;\int_{\mathfrak m} S(\alpha)^2 e(-N\alpha)\,d\alpha.
$$

\subsection*{Major arcs.}

By the Major–Arc Evaluation (Part D.7), we have, uniformly for even $N$,

$$
\int_{\mathfrak M} S(\alpha)^2 e(-N\alpha)\,d\alpha
\;=\;\mathfrak S(N)\,\frac{N}{\log^2 N}\;+\;O\!\left(\frac{N}{\log^{2+\eta}N}\right),
$$

for some fixed $\eta>0$. Here $\mathfrak S(N)$ is the binary Goldbach singular series

$$
\mathfrak S(N)
\;=\;2\,\prod_{p\ge 3}\!\left(1-\frac{1}{(p-1)^2}\right)
\;\prod_{\substack{p\mid N\\ p\ge 3}}\!\!\left(1+\frac{1}{p-2}\right),
$$

which satisfies $\mathfrak S(N)>0$ for every even $N$, and $\mathfrak S(N)=0$ for odd $N$.

\subsection*{Minor arcs.}

Assume the minor-arc $L^2$ input (A.1):

$$
\int_{\mathfrak m} |S(\alpha)-B(\alpha)|^2\,d\alpha
\;\ll\;\frac{N}{(\log N)^{3+\varepsilon}}.
$$

Write $S^2=B^2+2B(S-B)+(S-B)^2$ and integrate over $\mathfrak m$.
By Cauchy–Schwarz and Parseval,

$$
\Big|\int_{\mathfrak m} B(\alpha)\,\big(S(\alpha)-B(\alpha)\big)\,e(-N\alpha)\,d\alpha\Big|
\ \le\ \Big(\int_0^1 |B(\alpha)|^2\,d\alpha\Big)^{1/2}
\Big(\int_{\mathfrak m}|S(\alpha)-B(\alpha)|^2\,d\alpha\Big)^{1/2}
\ \ll\ \frac{N}{(\log N)^{2+\varepsilon/2}},
$$

since $\int_0^1|B|^2\ll N/\log N$ by (B2)–(B3). The pure error $\int_{\mathfrak m}|S-B|^2$ is already $\ll N/(\log N)^{3+\varepsilon}$. Thus the minor arcs contribute $o\!\left(N/\log^2 N\right)$ under (A.1), without requiring any bound stronger than $\int_0^1|B|^2\ll N/\log N$.

\subsection*{Conclusion.}

Combining the two ranges,

$$
R(N)
\;=\;\mathfrak S(N)\,\frac{N}{\log^2 N}\;+\;o\!\left(\frac{N}{\log^2 N}\right).
$$

Since $\mathfrak S(N)>0$ for every even $N$, it follows that $R(N)>0$ for all sufficiently large even $N$. Hence **every sufficiently large even integer is a sum of two primes.** $\qed$

\subsection*{Remark.} 
If desired, the error can be recorded explicitly as

$$
R(N)\;=\;\mathfrak S(N)\,\frac{N}{\log^2 N}\;+\;O\!\left(\frac{N}{\log^{2+\eta}N}\right),
$$

with the $\eta>0$ coming from your major-arc saving and the minor-arc $L^2$ bound.

\section*{Appendix A. Technical Lemmas and Parameters}

\subsection*{A.1. Minor--arc large sieve reduction}

We record the precise form of the inequality used in Part~D.6.

\begin{lemma}[Minor--arc large sieve reduction]\label{lem:largesieve-minor}
Let $Q=N^{1/2-\varepsilon}$ and define major arcs
\[
\mathfrak M(q,a)=\Bigl\{\alpha\in[0,1):\,\Big|\alpha-\tfrac{a}{q}\Big|\le \tfrac{1}{qQ}\Bigr\},
\qquad \mathfrak M=\!\!\!\!\!\bigcup_{\substack{q\le Q\\ (a,q)=1}}\!\!\mathfrak M(q,a),
\qquad \mathfrak m=[0,1)\setminus\mathfrak M.
\]
Then for any finitely supported sequence $c_n$,
\[
\int_{\mathfrak m}\Big|\sum_{n}c_n e(\alpha n)\Big|^2 d\alpha
\ \ll\ \frac{1}{Q^2}\,
\sum_{q\le Q}\ \sum_{\substack{a\!\!\!\pmod q\\ (a,q)=1}}
\Big|\sum_{n} c_n\,e\!\left(\tfrac{an}{q}\right)\Big|^2.
\]
\end{lemma}

\begin{proof}[Sketch]
Partition $[0,1)$ into $\{\mathfrak M(q,a)\}$ and $\mathfrak m$. For $\alpha\in\mathfrak m$ one has
$|\alpha-\tfrac aq|\ge 1/(qQ)$ for all $q\le Q$. Expanding the square and integrating against the Dirichlet kernel yields Gallagher’s lemma in the form
\[
\int_{I} \Big|\sum c_n e(\alpha n)\Big|^2 d\alpha
\ \ll\ \frac{1}{|I|^2}\sum_{q\le 1/|I|}\ \sum_{a\pmod q}\Big|\sum c_n e(an/q)\Big|^2
\]
for each interval $I\subset[0,1)$. Applying this to each complementary arc of length $\gg (qQ)^{-1}$ gives the stated bound. 
\end{proof}

\subsection*{A.2. Sieve weight $\beta$ and properties}

Fix parameters
\[
D=N^{1/2-\varepsilon},\qquad z=N^{\eta}\quad(0<\eta\ll \varepsilon).
\]
Let $P(z)=\prod_{p<z}p$ and define the linear (Rosser--Iwaniec) sieve weight
\[
\beta(n)=\sum_{\substack{d\mid n\\ d\mid P(z)}} \lambda_d,\qquad 
\lambda_d\ll_\varepsilon d^{\varepsilon},\quad
\sum_{d\mid P(z)}\frac{|\lambda_d|}{d}\ll \log z.
\]

\begin{lemma}\label{lem:beta-properties}
With this choice of $\beta=\beta_{z,D}$ the following hold:
\begin{enumerate}[label=(B\arabic*)]
\item $\beta(n)\ge 0$ and $\beta(n)\gg \frac{\log D}{\log N}$ for $n\le N$ almost prime.
\item $\sum_{n\le N}\beta(n)=(1+o(1))\,\tfrac{N}{\log N}$ and uniformly for $(a,q)=1$, $q\le D$,
\[
\sum_{\substack{n\le N\\ n\equiv a\pmod q}}\beta(n)
=(1+o(1))\,\frac{N}{\varphi(q)\log N}.
\]
\item $\beta$ is well--factorable: $\beta=\sum_{d\le D}\lambda_d 1_{d\mid\cdot}$ with divisor--bounded $\lambda_d$, enabling major--arc analysis.
\item \emph{Parity--blindness.} For any fixed smooth $W$ supported on $[1/2,2]$,
\[
\sum_{n\le N}\beta(n)\lambda(n)W(n/N)
\ \ll\ \frac{N}{(\log N)^A}
\]
for all $A>0$, uniformly in $N$. This follows by expanding $\beta$, applying Cauchy over $d\le D$, and invoking Lemma~3.2 / Route~B on each inner sum.
\end{enumerate}
\end{lemma}

\subsection*{A.3. Major--arc uniform error}

\begin{lemma}[Major--arc approximants]\label{lem:major-errors}
Let $\alpha=a/q+\beta$ with $q\le Q$, $|\beta|\le Q/(qN)$. Then for any $A>0$,
\begin{align*}
S(\alpha)&=\frac{\mu(q)}{\varphi(q)}\,V(\beta)+O\!\Big(\frac{N}{(\log N)^A}\Big),\\
B(\alpha)&=\frac{\mu(q)}{\varphi(q)}\,V(\beta)+O\!\Big(\frac{N}{(\log N)^A}\Big),
\end{align*}
uniformly in $q,a,\beta$. Here $V(\beta)=\sum_{n\le N}e(n\beta)$. 
\end{lemma}

\begin{proof}[Sketch]
For $S(\alpha)$: apply the prime number theorem in AP up to modulus $q\le Q=N^{1/2-\varepsilon}$ (Siegel--Walfisz + Bombieri--Vinogradov in smooth form).  
For $B(\alpha)$: expand the linear sieve weight $\beta$, unfold the congruence condition, and use the well--factorability at level $D=N^{1/2-\varepsilon}$. In both cases the error is $O(N(\log N)^{-A})$ by classical zero--density and well--factorable sieve estimates.
\end{proof}

\subsection*{A.4. Parameter box}

For clarity we record the global parameter choices:
\begin{itemize}
\item Minor--arc cutoff: $Q=N^{1/2-\varepsilon}$ with fixed $\varepsilon\in(0,10^{-2})$.
\item Sieve level: $D=N^{1/2-\varepsilon}$, small prime cutoff $z=N^\eta$ with $0<\eta\ll\varepsilon$.
\item Heath--Brown identity: cut parameters $U=V=W=N^{1/3}$ producing standard Type~I/II/III ranges.
\item Amplifier: primes in $[P,2P]$ with $P=X^\vartheta$, $0<\vartheta<1/6-\kappa$.
\item Type~III saving: $\delta=\tfrac{1}{1000}\min\{\kappa,\tfrac12-3\vartheta\}$.
\end{itemize}
\bigskip

\appendix
\section*{Appendix B. Outstanding items and assumptions}

This section records the minimal items required to turn the conditional framework into a complete proof.

\begin{enumerate}[label=\textbf{B.\arabic*}]
  \item \textbf{Minor-arc centerpiece (A.1).} Provide a full proof of
  $\int_{\mathfrak m}|S(\alpha)-B(\alpha)|^2\,d\alpha\ll N(\log N)^{-3-\varepsilon}$
  via the Type I/II/III mechanisms in Parts B–D, with parameters consistent across sections.

  \item \textbf{Lemma 3.2 (BV with parity, second moment).} State and prove with precise hypotheses (smooth weights, divisor bounds, coprimality gates), supplying the pretentious exceptional-set bounds and a cited hybrid large sieve, uniform for $Q\le N^{1/2}(\log N)^{-B}$.

  \item \textbf{Lemma S2.4 (prime-averaged short-shift).} Prove the short-shift $\Delta$ second-moment input with full parameter tracking; establish kernel localization uniform in level for holomorphic, Maaß (new/old), and Eisenstein families; bound the off-diagonal to obtain a fixed $\delta>0$ in $\mathrm{OD}\ll (Q^2+X)^{1-\delta}|\mathcal P|^{2-\delta}$.

  \item \textbf{Amplifier signs.} Provide a deterministic construction (or a precise reference) of balanced signs $\{\varepsilon_p\}$ with the requisite short-shift correlations at the prime scale used.

  \item \textbf{Major-arc approximants.} Record and justify the uniform $O\big(N(\log N)^{-A}\big)$ approximations for $S$ and $B$ on $\mathfrak M$, including the well-factorable linear-sieve major-arc computation.

  \item \textbf{Parameter ledger.} Fix a single admissible tuple $(\varepsilon,\eta,\kappa,\vartheta,\delta,A,B)$ validating every inequality (dyadic counts, large-sieve costs, amplifier length, and savings).
\end{enumerate}

The final positivity statement for $R(N)$ is therefore \emph{conditional} on B.1–B.6.

\end{document}

% --------- APPENDIX B INSERTED BEFORE \end{document} IN PREVIOUS LINE; MOVE IT ABOVE IF NEEDED ---------

